{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика: Погружение в глубокое обучение\n",
    "В семинаре, будем использовать набор данных `fashion_mnist`, загрузим их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train_cat), (x_test, y_test_cat) = fashion_mnist.load_data()\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "\n",
    "num_classes = 10\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', \n",
    "               'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем случаные примеры для каждого класса и посмотрим на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(y_train_cat[:]==i)[0]\n",
    "    features_idx = x_train[idx,::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    im = features_idx[img_num]\n",
    "    ax.set_title(class_names[i])\n",
    "    plt.imshow(im, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Построим нашу первую нейросеть\n",
    "Импорт `Keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential # Модель, где все слои соединены друг с другом\n",
    "from keras.layers import Dense, Flatten, Activation # Слой, где все нйероны предыдущего уровня соединены с нейронами следующего\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD,Adam,RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проведем небольшие предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train_cat, num_classes=num_classes)\n",
    "y_test = np_utils.to_categorical(y_test_cat, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "# Добавляем слои\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Компилируем модель\n",
    "optimizer = SGD(lr=0.1)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос: \n",
    "Почему: $784 \\times 20 = 156 80$, а сетка показывает число параметров: $15700$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель, задав параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1000 # Выбираем размер Батча\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Обучаем модель! \n",
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измените сеть выше, добавив еще один скрытый слой `Dense()` с 10 нейронами и перезапустите обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что мы можем улучшить? \n",
    "- Отнормировать признаки\n",
    "- Заменить сигмоиды на ReLu\n",
    "- Задать правила инициации весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормирование\n",
    "<img src='normalize.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализуйте данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции активации\n",
    "<img src='activations.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициациия весов\n",
    "__Случайно__  \n",
    "$ w = a * random$, но тогда если $a \\gg 1$, то на выходе $b\\gg1$ и если $a \\ll 1 $, то $b \\approx 0 $  \n",
    "\n",
    "__Xavier__  \n",
    "$a = \\frac{1}{\\sqrt{n}}$, где $n$ - кол-во нейронов на входе\n",
    "\n",
    "__He__  \n",
    "$a = \\frac{1}{\\sqrt{\\frac{n}{2}}}$, где $n$ - кол-во нейронов на входе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.initializers import he_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию `create_model()` создания и компиляции нейронной сети со следующей архитектурой:\n",
    "- Полносвязный слой с 20 нейронами\n",
    "- Полносвязный слой с 10 нейронами\n",
    "- Полносвязный слой с 10 нейронами\n",
    "Для компиляции используйте категориальный лосс и метрику `accuracy`. `optimizer` должен задаваться в параметре. \n",
    "Добавьте к каждому `Dense` слою функцию инициации весов `he_normal` и функцию активации `ReLU`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, optimizer):\n",
    "    # Ваш код здесь\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(lr=0.1)\n",
    "model = create_model(input_shape, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viz_history(history):\n",
    "    plt.plot(history.history['acc'], label='train')\n",
    "    plt.plot(history.history['val_acc'], label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "viz_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Влияние скорости обучения\n",
    "Посмотрим, как влияет параметр `learning_rate` на качество нашей модели на обучающей выборке.  \n",
    "Задайте `learning_rate` значениями `[0.001, 0.01, 0.1, 1]` и постройте графики acc для каждого значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "    \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Влияние метода оптимизации градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='optimizers7.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum\n",
    "Вместо того, чтобы использовать только градиент текущего шага, мы будем накапливать импульс градиента прошлых шагов для определения направления движения. \n",
    "В связи со стохастической природой, обновления градиента происходят \"зигзагообразно\", с помощью момента мы усиливаем движение вдоль основного направления. На практике коэффициент у момента инициализируется на уровне 0,5 и постепенно увеличивается до 0,9 в течение нескольких эпох. \n",
    "  \n",
    "#### RMSProp (Root Mean Square Propogation)   \n",
    "Мы обновляяем меньше веса, которые слишком часто обновляются, и будем использовать усреднённый по истории квадрат градиента.\n",
    "\n",
    "#### Adam (Adaptive moment estimation)\n",
    "Cочетает в себе и идею накопления движения и идею более слабого обновления весов для типичных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики зависимости качества обучения на валидационной выборе для разных оптимизаторов:\n",
    "    - SGD with Momentum\n",
    "    - Adam\n",
    "    - RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применим, все полученные знания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задайте в качестве оптимизатора `Adam()` и обучите модель: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объявляем, борьбу с переобучением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте  после каждого `Dense` слоя в нашу сеть `Dropout` или `BatchNormalization`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки\n",
    "- [Курс \"Deep learning на пальцах\", лекция 4](https://youtu.be/tnrbx7V9RbA)\n",
    "- [Статья: Оптимизация градиентного спуска](http://ruder.io/optimizing-gradient-descent/)\n",
    "- [Статья: Методы оптимизации нейронных сетей](https://habr.com/ru/post/318970/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
